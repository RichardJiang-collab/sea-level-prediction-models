import pandas as pdimport matplotlib.pyplot as pltfrom scipy import statsimport numpy as npfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import StandardScalerfrom sklearn.ensemble import RandomForestRegressorfrom sklearn.model_selection import GridSearchCVfrom statsmodels.tsa.arima.model import ARIMAfrom statsmodels.tsa.statespace.sarimax import SARIMAXfrom sklearn.linear_model import Lasso, Ridgefrom sklearn.ensemble import GradientBoostingRegressorfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_scoreimport joblib# 1: Import Datadatapath = "/Users/richardjiang/Downloads/4-Different Realms/2-Environment/Personal Projects/1 - Simple Sea Level Prediction Model/Global_sea_level_rise.csv"data = pd.read_csv(datapath)#%% 2: Inspect Data# data['date'] = pd.to_datetime(data['date'])  # convert date to datetime# plt.figure(figsize=(15, 8))# plt.plot(data['date'], data['mmfrom1993-2008average'], color='blue')# plt.xlabel('Year', fontsize=12)# plt.ylabel('Sea Level Difference (mm) from 1993-2008 Average', fontsize=12)# plt.title('Global Sea Level Rise (1880-2022)', fontsize=16)# plt.grid(True, linestyle='--', alpha=0.7)# plt.tick_params(axis='both', which='major', labelsize=10)# plt.axhline(y=0, color='r', linestyle='--', alpha=0.7)# plt.text(data['date'].iloc[-1], 5, '1993-2008 Average', color='r', ha='right', va='bottom')# plt.tight_layout()# plt.show()# print(data['mmfrom1993-2008average'].describe())  # print some basic statistics#%% 3: Data Preprocessing# 3.1 Normalizing Datadata['date'] = pd.to_datetime(data['date'])data['year'] = data['date'].dt.year# 3.2 Removing Outliers (Datapoints that Deviate too Much from Normal)z_scores = stats.zscore(data['mmfrom1993-2008average'])threshold = 2outliers = z_scores[np.abs(z_scores) > threshold]data.drop(outliers.index, inplace=True)# 3.3 Split DataX, y = data.drop(columns=["mmfrom1993-2008average"]), data["mmfrom1993-2008average"]y = pd.DataFrame(y)X = X.select_dtypes(exclude=['datetime64'])  # 去除日期时间类型的列X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)# 3.4 Normalize Datascaler = StandardScaler()X_train = scaler.fit_transform(X_train)X_test = scaler.transform(X_test)#%% 4: Modelingmodels = {    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),    'ARIMA': ARIMA(y_train, order=(1,1,1)),    'SARIMA': SARIMAX(y_train, order=(1,1,1), seasonal_order=(1,1,1,12)),    'Lasso': Lasso(alpha=0.1),    'Ridge': Ridge(alpha=0.1),    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)}# Hyperparameter Tuning (for RandomForestRegressor)# param_grid = {#     'n_estimators': [100, 200, 300],#     'max_depth': [10, 20, 30, None],#     'min_samples_split': [2, 5, 10]# }# grid_search = GridSearchCV(RandomForestRegressor(random_state=1), param_grid, cv=5)# grid_search.fit(X_train, y_train)# best_rf_model = grid_search.best_estimator_#%% 5. Evaluation# 5.1 Function to evaluate the performancedef evaluate_model(y_true, y_pred, model_name):    mae = mean_absolute_error(y_true, y_pred)    rmse = np.sqrt(mean_squared_error(y_true, y_pred))    r2 = r2_score(y_true, y_pred)    print(f"{model_name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}")    return mae, rmse, r2# 5.2 Visualize the resultsdef plot_model(y_true, y_pred, model_name):    plt.figure(figsize=(10, 6))    plt.scatter(y_true, y_pred, alpha=0.5)    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)    plt.xlabel("Actual Sea Level")    plt.ylabel("Predicted Sea Level")    plt.title(f"{model_name}: Actual vs. Predicted Sea Levels")    plt.tight_layout()    plt.show()# 5.3 Apply the functions to each modelresults = {}for name, model in models.items():    if name in ['ARIMA', 'SARIMA']:        model_fit = model.fit()        y_pred = model_fit.forecast(steps=len(y_test))    else:        model.fit(X_train, y_train)        y_pred = model.predict(X_test)        mae, rmse, r2 = evaluate_model(y_test, y_pred, name)    results[name] = {'MAE': mae, 'RMSE': rmse, 'R²': r2}    plot_model(y_test, y_pred, name)        # Save the model    joblib.dump(model, f'{name.lower().replace(" ", "_")}_model.joblib')    # Create a summary DataFrame of resultssummary_df = pd.DataFrame(results).Tprint("\nSummary of Model Performance:")print(summary_df)# Plot summary of model performanceplt.figure(figsize=(12, 6))summary_df.plot(kind='bar', ax=plt.gca())plt.title('Model Performance Comparison')plt.xlabel('Models')plt.ylabel('Error Rate')plt.legend(title='Metrics')plt.tight_layout()plt.show()#%% 6. Model Deploymentdef predict_sea_level(features):    model = joblib.load('sea_level_prediction_model.joblib')    return model.predict(features)