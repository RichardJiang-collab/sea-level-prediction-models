import pandas as pdimport matplotlib.pyplot as pltfrom scipy import statsimport numpy as npfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import Normalizerfrom sklearn.ensemble import RandomForestRegressorfrom sklearn.model_selection import GridSearchCVfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score# 1: Import Datadatapath = "/Users/richardjiang/Downloads/4-Different Realms/2-Environment/Personal Projects/1 - Simple Sea Level Prediction Model/Global_sea_level_rise.csv"data = pd.read_csv(datapath)#%% 2: Inspect Data# data['date'] = pd.to_datetime(data['date'])  # convert date to datetime# plt.figure(figsize=(15, 8))# plt.plot(data['date'], data['mmfrom1993-2008average'], color='blue')# plt.xlabel('Year', fontsize=12)# plt.ylabel('Sea Level Difference (mm) from 1993-2008 Average', fontsize=12)# plt.title('Global Sea Level Rise (1880-2022)', fontsize=16)# plt.grid(True, linestyle='--', alpha=0.7)# plt.tick_params(axis='both', which='major', labelsize=10)# plt.axhline(y=0, color='r', linestyle='--', alpha=0.7)# plt.text(data['date'].iloc[-1], 5, '1993-2008 Average', color='r', ha='right', va='bottom')# plt.tight_layout()# plt.show()# print(data['mmfrom1993-2008average'].describe())  # print some basic statistics#%% 3: Data Preprocessing# 3.1 Normalizing Datadata['date'] = pd.to_datetime(data['date'])# 3.2 Removing Outliers (Datapoints that Deviate too Much from Normal)z_scores = stats.zscore(data['mmfrom1993-2008average'])threshold = 2outliers = z_scores[np.abs(z_scores) > threshold]data.drop(outliers.index, inplace=True)# 3.3 Split DataX, y = data.drop(columns=["mmfrom1993-2008average"]), data["mmfrom1993-2008average"].ravel()y = pd.DataFrame(y)X = X.select_dtypes(exclude=['datetime64'])  # 去除日期时间类型的列X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)# 3.4 Normalize Datanormalizer = Normalizer()y_train = normalizer.fit_transform(y_train)y_test = normalizer.transform(y_test)#%% 4: Modeling# 4.1 Train Modelmodel = RandomForestRegressor(n_estimators=100, random_state=1)model.fit(X_train, y_train)# 4.2 Hyperparameter Tuning (n_estimators = 100)param_grid = {    'n_estimators': [100, 200, 300],    'max_depth': [10, 20, 30, None],    'min_samples_split': [2, 5, 10]}grid_search = GridSearchCV(RandomForestRegressor(random_state=1), param_grid, cv=5)grid_search.fit(X_train, y_train)best_rf_model = grid_search.best_estimator_#%% 5. Evaluation# 5.1 Calculate the Performancey_pred = best_rf_model.predict(X_test)mae = mean_absolute_error(y_test, y_pred)rmse = np.sqrt(mean_squared_error(y_test, y_pred))r2 = r2_score(y_test, y_pred)# print(f"MAE: {mae}")# print(f"RMSE: {rmse}")# print(f"R² Score: {r2}")# 5.2 Visualize the Resultplt.figure(figsize=(10, 6))plt.scatter(y_test, y_pred, alpha=0.5)plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)plt.xlabel("Actual Sea Level")plt.ylabel("Predicted Sea Level")plt.title("Actual vs. Predicted Sea Levels")plt.show()